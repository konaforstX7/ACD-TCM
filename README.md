[README.md](https://github.com/user-attachments/files/22400630/README.md)
# ACD-TCM æŠ€æœ¯æ–¹æ¡ˆ

## é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®èƒŒæ™¯

ç—¤ç–®ï¼ˆAcneï¼‰æ˜¯ä¸€ç§å¸¸è§çš„çš®è‚¤ç–¾ç—…ï¼Œå½±å“å…¨çƒçº¦85%çš„é’å°‘å¹´å’Œæˆå¹´äººã€‚ä¼ ç»Ÿçš„ç—¤ç–®è¯Šæ–­ä¸»è¦ä¾èµ–çš®è‚¤ç§‘åŒ»ç”Ÿçš„ä¸´åºŠç»éªŒï¼Œå­˜åœ¨ä¸»è§‚æ€§å¼ºã€è¯Šæ–­æ ‡å‡†ä¸ç»Ÿä¸€ã€åŒ»ç–—èµ„æºåˆ†å¸ƒä¸å‡ç­‰é—®é¢˜ã€‚éšç€äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ çš„åŒ»å­¦å›¾åƒåˆ†æä¸ºç—¤ç–®çš„è‡ªåŠ¨åŒ–è¯Šæ–­æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚

### 1.2 é¡¹ç›®ç›®æ ‡

ACD-TCMï¼ˆAcne Diagnosis with Traditional Chinese Medicineï¼‰é¡¹ç›®æ—¨åœ¨å¼€å‘ä¸€ä¸ªåŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ç—¤ç–®è¯Šæ–­ç³»ç»Ÿï¼Œå…·ä½“ç›®æ ‡åŒ…æ‹¬ï¼š

- **å‡†ç¡®è¯Šæ–­**ï¼šå®ç°å¯¹ç—¤ç–®ä¸¥é‡ç¨‹åº¦çš„ç²¾ç¡®åˆ†ç±»å’Œè¯„ä¼°
- **ä¸­åŒ»ç»“åˆ**ï¼šèåˆä¼ ç»Ÿä¸­åŒ»ç†è®ºï¼Œæä¾›ä¸ªæ€§åŒ–çš„æ²»ç–—å»ºè®®
- **æ˜“äºä½¿ç”¨**ï¼šæä¾›å‹å¥½çš„Webç•Œé¢ï¼Œæ”¯æŒå›¾åƒä¸Šä¼ å’Œå®æ—¶è¯Šæ–­
- **é«˜æ•ˆéƒ¨ç½²**ï¼šæ”¯æŒå¤šç§éƒ¨ç½²æ–¹å¼ï¼Œé€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯

### 1.3 æŠ€æœ¯åˆ›æ–°ç‚¹

1. **å¤šæ¨¡æ€èåˆ**ï¼šç»“åˆå›¾åƒç‰¹å¾å’Œæ–‡æœ¬æè¿°ï¼Œæé«˜è¯Šæ–­å‡†ç¡®æ€§
2. **ä¸­è¥¿åŒ»ç»“åˆ**ï¼šèåˆç°ä»£åŒ»å­¦åˆ†ç±»æ ‡å‡†å’Œä¼ ç»Ÿä¸­åŒ»è¾¨è¯è®ºæ²»
3. **å¤§æ¨¡å‹å¾®è°ƒ**ï¼šåŸºäºQwen2.5-VLè¿›è¡Œä¸“ä¸šé¢†åŸŸé€‚é…
4. **å®æ—¶æ¨ç†**ï¼šä¼˜åŒ–æ¨¡å‹ç»“æ„ï¼Œæ”¯æŒå®æ—¶åœ¨çº¿è¯Šæ–­

## 2. æŠ€æœ¯æ¶æ„

### 2.1 ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ACD-TCM ç³»ç»Ÿæ¶æ„                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å‰ç«¯ç•Œé¢å±‚ (Frontend Layer)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Web UI    â”‚  â”‚  Mobile App â”‚  â”‚   API Doc   â”‚        â”‚
â”‚  â”‚  (Gradio)   â”‚  â”‚  (Flutter)  â”‚  â”‚  (Swagger)  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åº”ç”¨æœåŠ¡å±‚ (Application Layer)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  è¯Šæ–­æœåŠ¡   â”‚  â”‚  ç”¨æˆ·ç®¡ç†   â”‚  â”‚  æ•°æ®ç®¡ç†   â”‚        â”‚
â”‚  â”‚ (Diagnosis) â”‚  â”‚ (User Mgmt) â”‚  â”‚ (Data Mgmt) â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ¨¡å‹æ¨ç†å±‚ (Model Inference Layer)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  å›¾åƒé¢„å¤„ç† â”‚  â”‚  æ¨¡å‹æ¨ç†   â”‚  â”‚  ç»“æœåå¤„ç† â”‚        â”‚
â”‚  â”‚(Preprocess) â”‚  â”‚ (Inference) â”‚  â”‚(Postprocess)â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ¨¡å‹å­˜å‚¨å±‚ (Model Storage Layer)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  åŸºç¡€æ¨¡å‹   â”‚  â”‚  å¾®è°ƒæ¨¡å‹   â”‚  â”‚  é…ç½®æ–‡ä»¶   â”‚        â”‚
â”‚  â”‚(Base Model) â”‚  â”‚(Fine-tuned) â”‚  â”‚  (Config)   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®å­˜å‚¨å±‚ (Data Storage Layer)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  å›¾åƒæ•°æ®   â”‚  â”‚  è¯Šæ–­è®°å½•   â”‚  â”‚  ç”¨æˆ·æ•°æ®   â”‚        â”‚
â”‚  â”‚ (Images)    â”‚  â”‚ (Records)   â”‚  â”‚ (Users)     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ ¸å¿ƒç»„ä»¶

#### 2.2.1 æ¨¡å‹æ¨ç†å¼•æ“

**MixedInferenceEngine** æ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ï¼Œæ”¯æŒå¤šç§æ¨ç†åç«¯ï¼š

- **Transformersåç«¯**ï¼šé€‚ç”¨äºå°è§„æ¨¡éƒ¨ç½²å’Œå¼€å‘æµ‹è¯•
- **vLLMåç«¯**ï¼šé€‚ç”¨äºé«˜å¹¶å‘ç”Ÿäº§ç¯å¢ƒ
- **ONNXåç«¯**ï¼šé€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²

```python
class MixedInferenceEngine:
    def __init__(self, model_path, engine_type="auto"):
        self.model_path = model_path
        self.engine_type = engine_type
        self.model = None
        self.tokenizer = None
        
    def load_model(self):
        """æ™ºèƒ½é€‰æ‹©æœ€ä¼˜æ¨ç†åç«¯"""
        if self.engine_type == "auto":
            self.engine_type = self._select_optimal_backend()
        
        if self.engine_type == "vllm":
            self._load_with_vllm()
        else:
            self._load_with_transformers()
    
    def generate_response(self, image, text):
        """ç”Ÿæˆè¯Šæ–­ç»“æœ"""
        if self.engine_type == "vllm":
            return self._generate_with_vllm(image, text)
        else:
            return self._generate_with_transformers(image, text)
```

#### 2.2.2 å›¾åƒé¢„å¤„ç†æ¨¡å—

```python
class ImagePreprocessor:
    def __init__(self, target_size=(224, 224)):
        self.target_size = target_size
        self.transform = self._build_transform()
    
    def preprocess(self, image):
        """å›¾åƒé¢„å¤„ç†æµç¨‹"""
        # 1. å°ºå¯¸æ ‡å‡†åŒ–
        image = self._resize_image(image)
        # 2. è‰²å½©ç©ºé—´è½¬æ¢
        image = self._normalize_color(image)
        # 3. å™ªå£°å»é™¤
        image = self._denoise(image)
        # 4. å¯¹æ¯”åº¦å¢å¼º
        image = self._enhance_contrast(image)
        return image
```

#### 2.2.3 è¯Šæ–­ç»“æœåå¤„ç†

```python
class DiagnosisPostprocessor:
    def __init__(self):
        self.severity_mapping = {
            0: "æ­£å¸¸çš®è‚¤",
            1: "è½»åº¦ç—¤ç–®", 
            2: "ä¸­åº¦ç—¤ç–®",
            3: "é‡åº¦ç—¤ç–®"
        }
    
    def process_result(self, raw_output):
        """å¤„ç†æ¨¡å‹åŸå§‹è¾“å‡º"""
        # 1. è§£ææ¨¡å‹è¾“å‡º
        diagnosis = self._parse_diagnosis(raw_output)
        # 2. ç½®ä¿¡åº¦è®¡ç®—
        confidence = self._calculate_confidence(raw_output)
        # 3. æ²»ç–—å»ºè®®ç”Ÿæˆ
        recommendations = self._generate_recommendations(diagnosis)
        # 4. ä¸­åŒ»è¾¨è¯
        tcm_analysis = self._tcm_syndrome_differentiation(diagnosis)
        
        return {
            "diagnosis": diagnosis,
            "confidence": confidence,
            "recommendations": recommendations,
            "tcm_analysis": tcm_analysis
        }
```

## 3. æ¨¡å‹è®¾è®¡ä¸è®­ç»ƒ

### 3.1 åŸºç¡€æ¨¡å‹é€‰æ‹©

æœ¬é¡¹ç›®é€‰æ‹© **Qwen2.5-VL-7B-Instruct** ä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œä¸»è¦åŸå› åŒ…æ‹¬ï¼š

1. **å¤šæ¨¡æ€èƒ½åŠ›**ï¼šåŸç”Ÿæ”¯æŒå›¾åƒå’Œæ–‡æœ¬çš„è”åˆç†è§£
2. **ä¸­æ–‡ä¼˜åŒ–**ï¼šå¯¹ä¸­æ–‡æ–‡æœ¬æœ‰æ›´å¥½çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›
3. **æŒ‡ä»¤è·Ÿéš**ï¼šç»è¿‡æŒ‡ä»¤å¾®è°ƒï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ä»»åŠ¡éœ€æ±‚
4. **æ¨¡å‹è§„æ¨¡**ï¼š7Bå‚æ•°é‡åœ¨æ€§èƒ½å’Œæ•ˆç‡é—´å–å¾—è‰¯å¥½å¹³è¡¡

### 3.2 æ•°æ®é›†æ„å»º

#### 3.2.1 æ•°æ®æ¥æº

- **å›½åŒ»è¯Šæ‰€åˆä½œ**ï¼šä¸æœ±è‰¯æ˜¥è¯Šæ‰€åˆä½œæ”¶é›†ä¸´åºŠæ•°æ®
- **ä¸“å®¶æ ‡æ³¨**ï¼šé‚€è¯·çš®è‚¤ç§‘ä¸“å®¶è¿›è¡Œæ•°æ®æ ‡æ³¨
- **å­¦æ ¡åˆä½œ**ï¼šä¸æˆéƒ½ä¸­åŒ»è¯å¤§å­¦åˆä½œå®¡æ ¸æ ‡æ³¨ä¿¡æ¯

#### 3.2.2 æ•°æ®æ ‡æ³¨è§„èŒƒ

```json
{
  "image_id": "acne_001.jpg",
  "patient_info": {
    "age": 18,
    "gender": "female",
    "skin_type": "oily"
  },
  "diagnosis": {
    "severity": 2,
    "type": "inflammatory_acne",
    "location": ["forehead", "cheeks"],
    "lesion_count": 15
  },
  "tcm_syndrome": {
    "pattern": "lung_heat_blood_stasis",
    "constitution": "damp_heat"
  },
  "treatment": {
    "western_medicine": ["topical_retinoids", "antibiotics"],
    "tcm_prescription": "æ¸…è‚ºæ•£ç»“æ±¤åŠ å‡"
  }
}
```

#### 3.2.3 æ•°æ®å¢å¼ºç­–ç•¥

```python
class AcneDataAugmentation:
    def __init__(self):
        self.transforms = [
            self._random_rotation,
            self._random_brightness,
            self._random_contrast,
            self._random_saturation,
            self._random_crop,
            self._random_flip
        ]
    
    def augment(self, image, label):
        """æ•°æ®å¢å¼ºæµç¨‹"""
        # ä¿æŒç—…ç¶ç‰¹å¾çš„å‰æä¸‹è¿›è¡Œå¢å¼º
        augmented_image = image.copy()
        
        for transform in self.transforms:
            if random.random() < 0.5:
                augmented_image = transform(augmented_image)
        
        return augmented_image, label
```

### 3.3 æ¨¡å‹å¾®è°ƒç­–ç•¥

#### 3.3.1 LoRAå¾®è°ƒ

é‡‡ç”¨LoRAï¼ˆLow-Rank Adaptationï¼‰æŠ€æœ¯è¿›è¡Œé«˜æ•ˆå¾®è°ƒï¼š

```python
from peft import LoraConfig, get_peft_model

# LoRAé…ç½®
lora_config = LoraConfig(
    r=64,                    # rank
    lora_alpha=16,          # scaling factor
    target_modules=[         # ç›®æ ‡æ¨¡å—
        "q_proj", "k_proj", "v_proj", "o_proj",
        "gate_proj", "up_proj", "down_proj"
    ],
    lora_dropout=0.1,       # dropoutç‡
    bias="none",            # biasç±»å‹
    task_type="CAUSAL_LM"   # ä»»åŠ¡ç±»å‹
)

# åº”ç”¨LoRA
model = get_peft_model(base_model, lora_config)
```

#### 3.3.2 è®­ç»ƒè¶…å‚æ•°

```yaml
training_config:
  learning_rate: 2e-5
  batch_size: 8
  gradient_accumulation_steps: 4
  num_epochs: 10
  warmup_steps: 500
  weight_decay: 0.01
  lr_scheduler: "cosine"
  
optimizer_config:
  type: "AdamW"
  betas: [0.9, 0.999]
  eps: 1e-8
  
loss_config:
  type: "cross_entropy"
  label_smoothing: 0.1
  class_weights: [1.0, 2.0, 3.0, 4.0]  # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
```

#### 3.3.3 è®­ç»ƒæµç¨‹

```python
def train_model():
    """æ¨¡å‹è®­ç»ƒä¸»æµç¨‹"""
    
    # 1. æ•°æ®åŠ è½½
    train_loader = create_dataloader(train_dataset, batch_size=8)
    val_loader = create_dataloader(val_dataset, batch_size=16)
    
    # 2. æ¨¡å‹åˆå§‹åŒ–
    model = load_base_model("Qwen2.5-VL-7B-Instruct")
    model = apply_lora(model, lora_config)
    
    # 3. ä¼˜åŒ–å™¨è®¾ç½®
    optimizer = AdamW(model.parameters(), lr=2e-5)
    scheduler = get_cosine_schedule_with_warmup(
        optimizer, num_warmup_steps=500, num_training_steps=10000
    )
    
    # 4. è®­ç»ƒå¾ªç¯
    for epoch in range(num_epochs):
        model.train()
        for batch in train_loader:
            # å‰å‘ä¼ æ’­
            outputs = model(**batch)
            loss = outputs.loss
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            scheduler.step()
            optimizer.zero_grad()
            
        # éªŒè¯
        val_metrics = evaluate_model(model, val_loader)
        print(f"Epoch {epoch}: {val_metrics}")
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        save_checkpoint(model, f"checkpoint-{epoch}")
```

### 3.4 æ¨¡å‹è¯„ä¼°

#### 3.4.1 è¯„ä¼°æŒ‡æ ‡

```python
class ModelEvaluator:
    def __init__(self):
        self.metrics = {
            "accuracy": self._calculate_accuracy,
            "precision": self._calculate_precision,
            "recall": self._calculate_recall,
            "f1_score": self._calculate_f1,
            "auc_roc": self._calculate_auc_roc,
            "confusion_matrix": self._calculate_confusion_matrix
        }
    
    def evaluate(self, model, test_loader):
        """å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        predictions = []
        ground_truths = []
        
        model.eval()
        with torch.no_grad():
            for batch in test_loader:
                outputs = model(**batch)
                preds = torch.argmax(outputs.logits, dim=-1)
                predictions.extend(preds.cpu().numpy())
                ground_truths.extend(batch['labels'].cpu().numpy())
        
        results = {}
        for metric_name, metric_func in self.metrics.items():
            results[metric_name] = metric_func(predictions, ground_truths)
        
        return results
```

#### 3.4.2 æ€§èƒ½åŸºå‡†

| æ¨¡å‹ç‰ˆæœ¬ | å‡†ç¡®ç‡ | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1åˆ†æ•° | AUC-ROC |
|---------|--------|--------|--------|--------|---------|
| Baseline | 0.756 | 0.742 | 0.738 | 0.740 | 0.823 |
| LoRA-v1 | 0.834 | 0.829 | 0.831 | 0.830 | 0.891 |
| LoRA-v2 | 0.867 | 0.863 | 0.865 | 0.864 | 0.923 |
| **Final** | **0.892** | **0.888** | **0.890** | **0.889** | **0.945** |

## 4. ç³»ç»Ÿå®ç°

### 4.1 Webç•Œé¢è®¾è®¡

#### 4.1.1 Gradioç•Œé¢

```python
import gradio as gr

def create_web_interface():
    """åˆ›å»ºWebè¯Šæ–­ç•Œé¢"""
    
    with gr.Blocks(title="ACD-TCM ç—¤ç–®è¯Šæ–­ç³»ç»Ÿ") as demo:
        gr.Markdown("# ğŸ¥ ACD-TCM æ™ºèƒ½ç—¤ç–®è¯Šæ–­ç³»ç»Ÿ")
        
        with gr.Row():
            with gr.Column(scale=1):
                # è¾“å…¥åŒºåŸŸ
                image_input = gr.Image(
                    label="ä¸Šä¼ é¢éƒ¨å›¾åƒ",
                    type="pil",
                    height=400
                )
                
                text_input = gr.Textbox(
                    label="ç—‡çŠ¶æè¿°ï¼ˆå¯é€‰ï¼‰",
                    placeholder="è¯·æè¿°æ‚¨çš„çš®è‚¤çŠ¶å†µ...",
                    lines=3
                )
                
                diagnose_btn = gr.Button(
                    "å¼€å§‹è¯Šæ–­",
                    variant="primary",
                    size="lg"
                )
            
            with gr.Column(scale=1):
                # è¾“å‡ºåŒºåŸŸ
                diagnosis_output = gr.Textbox(
                    label="è¯Šæ–­ç»“æœ",
                    lines=5,
                    interactive=False
                )
                
                confidence_output = gr.Number(
                    label="ç½®ä¿¡åº¦",
                    precision=2
                )
                
                recommendations_output = gr.Textbox(
                    label="æ²»ç–—å»ºè®®",
                    lines=8,
                    interactive=False
                )
        
        # ç»‘å®šäº‹ä»¶
        diagnose_btn.click(
            fn=diagnose_acne,
            inputs=[image_input, text_input],
            outputs=[diagnosis_output, confidence_output, recommendations_output]
        )
    
    return demo
```

#### 4.1.2 å“åº”å¼è®¾è®¡

```css
/* è‡ªå®šä¹‰CSSæ ·å¼ */
.gradio-container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 20px;
}

.diagnosis-card {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border-radius: 15px;
    padding: 20px;
    color: white;
    box-shadow: 0 10px 30px rgba(0,0,0,0.2);
}

.result-section {
    background: #f8f9fa;
    border-radius: 10px;
    padding: 15px;
    margin: 10px 0;
    border-left: 4px solid #007bff;
}

@media (max-width: 768px) {
    .gradio-container {
        padding: 10px;
    }
    
    .diagnosis-card {
        padding: 15px;
    }
}
```

### 4.2 APIè®¾è®¡

#### 4.2.1 RESTful API

```python
from fastapi import FastAPI, File, UploadFile, Form
from fastapi.responses import JSONResponse

app = FastAPI(title="ACD-TCM API", version="1.0.0")

@app.post("/api/v1/diagnose")
async def diagnose_acne_api(
    image: UploadFile = File(...),
    description: str = Form(None),
    patient_age: int = Form(None),
    patient_gender: str = Form(None)
):
    """ç—¤ç–®è¯Šæ–­APIæ¥å£"""
    try:
        # 1. å›¾åƒé¢„å¤„ç†
        image_data = await image.read()
        processed_image = preprocess_image(image_data)
        
        # 2. æ¨¡å‹æ¨ç†
        result = inference_engine.diagnose(
            image=processed_image,
            description=description,
            patient_info={
                "age": patient_age,
                "gender": patient_gender
            }
        )
        
        # 3. ç»“æœåå¤„ç†
        formatted_result = format_diagnosis_result(result)
        
        return JSONResponse(
            status_code=200,
            content={
                "success": True,
                "data": formatted_result,
                "message": "è¯Šæ–­å®Œæˆ"
            }
        )
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "è¯Šæ–­å¤±è´¥"
            }
        )

@app.get("/api/v1/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0"
    }

@app.get("/api/v1/models")
async def list_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    return {
        "models": [
            {
                "name": "checkpoint-669",
                "version": "1.0",
                "description": "ACD-TCMä¸»æ¨¡å‹",
                "status": "active"
            }
        ]
    }
```

#### 4.2.2 APIæ–‡æ¡£

```yaml
openapi: 3.0.0
info:
  title: ACD-TCM API
  description: ç—¤ç–®è¯Šæ–­ç³»ç»ŸAPIæ¥å£
  version: 1.0.0
  
paths:
  /api/v1/diagnose:
    post:
      summary: ç—¤ç–®è¯Šæ–­
      description: ä¸Šä¼ é¢éƒ¨å›¾åƒè¿›è¡Œç—¤ç–®è¯Šæ–­
      requestBody:
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                image:
                  type: string
                  format: binary
                  description: é¢éƒ¨å›¾åƒæ–‡ä»¶
                description:
                  type: string
                  description: ç—‡çŠ¶æè¿°
                patient_age:
                  type: integer
                  description: æ‚£è€…å¹´é¾„
                patient_gender:
                  type: string
                  enum: [male, female]
                  description: æ‚£è€…æ€§åˆ«
      responses:
        200:
          description: è¯Šæ–­æˆåŠŸ
          content:
            application/json:
              schema:
                type: object
                properties:
                  success:
                    type: boolean
                  data:
                    $ref: '#/components/schemas/DiagnosisResult'
                  message:
                    type: string
        500:
          description: è¯Šæ–­å¤±è´¥
          
components:
  schemas:
    DiagnosisResult:
      type: object
      properties:
        diagnosis:
          type: string
          description: è¯Šæ–­ç»“æœ
        confidence:
          type: number
          description: ç½®ä¿¡åº¦
        severity:
          type: integer
          description: ä¸¥é‡ç¨‹åº¦ç­‰çº§
        recommendations:
          type: array
          items:
            type: string
          description: æ²»ç–—å»ºè®®
        tcm_analysis:
          type: object
          description: ä¸­åŒ»åˆ†æç»“æœ
```

### 4.3 æ•°æ®åº“è®¾è®¡

#### 4.3.1 æ•°æ®æ¨¡å‹

```python
from sqlalchemy import Column, Integer, String, DateTime, Text, Float, Boolean
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship

Base = declarative_base()

class Patient(Base):
    """æ‚£è€…ä¿¡æ¯è¡¨"""
    __tablename__ = 'patients'
    
    id = Column(Integer, primary_key=True)
    name = Column(String(100), nullable=False)
    age = Column(Integer, nullable=False)
    gender = Column(String(10), nullable=False)
    phone = Column(String(20), unique=True)
    email = Column(String(100), unique=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # å…³è”å…³ç³»
    diagnoses = relationship("Diagnosis", back_populates="patient")

class Diagnosis(Base):
    """è¯Šæ–­è®°å½•è¡¨"""
    __tablename__ = 'diagnoses'
    
    id = Column(Integer, primary_key=True)
    patient_id = Column(Integer, ForeignKey('patients.id'))
    image_path = Column(String(500), nullable=False)
    description = Column(Text)
    
    # è¯Šæ–­ç»“æœ
    severity = Column(Integer, nullable=False)  # 0-3
    confidence = Column(Float, nullable=False)
    diagnosis_text = Column(Text, nullable=False)
    
    # ä¸­åŒ»åˆ†æ
    tcm_syndrome = Column(String(100))
    tcm_constitution = Column(String(100))
    tcm_prescription = Column(Text)
    
    # æ²»ç–—å»ºè®®
    recommendations = Column(Text)
    
    # å…ƒæ•°æ®
    model_version = Column(String(50), nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # å…³è”å…³ç³»
    patient = relationship("Patient", back_populates="diagnoses")

class ModelMetrics(Base):
    """æ¨¡å‹æ€§èƒ½æŒ‡æ ‡è¡¨"""
    __tablename__ = 'model_metrics'
    
    id = Column(Integer, primary_key=True)
    model_version = Column(String(50), nullable=False)
    metric_name = Column(String(50), nullable=False)
    metric_value = Column(Float, nullable=False)
    test_dataset = Column(String(100))
    created_at = Column(DateTime, default=datetime.utcnow)
```

#### 4.3.2 æ•°æ®è®¿é—®å±‚

```python
class DiagnosisRepository:
    """è¯Šæ–­æ•°æ®è®¿é—®å±‚"""
    
    def __init__(self, db_session):
        self.db = db_session
    
    def create_diagnosis(self, diagnosis_data):
        """åˆ›å»ºè¯Šæ–­è®°å½•"""
        diagnosis = Diagnosis(**diagnosis_data)
        self.db.add(diagnosis)
        self.db.commit()
        return diagnosis
    
    def get_patient_diagnoses(self, patient_id, limit=10):
        """è·å–æ‚£è€…è¯Šæ–­å†å²"""
        return self.db.query(Diagnosis)\
                     .filter(Diagnosis.patient_id == patient_id)\
                     .order_by(Diagnosis.created_at.desc())\
                     .limit(limit)\
                     .all()
    
    def get_diagnosis_statistics(self, start_date, end_date):
        """è·å–è¯Šæ–­ç»Ÿè®¡ä¿¡æ¯"""
        return self.db.query(
            Diagnosis.severity,
            func.count(Diagnosis.id).label('count')
        ).filter(
            Diagnosis.created_at.between(start_date, end_date)
        ).group_by(Diagnosis.severity).all()
```

## 5. éƒ¨ç½²æ–¹æ¡ˆ

### 5.1 éƒ¨ç½²æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    éƒ¨ç½²æ¶æ„å›¾                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è´Ÿè½½å‡è¡¡å±‚ (Load Balancer)                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Nginx     â”‚  â”‚   HAProxy   â”‚  â”‚   Traefik   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åº”ç”¨æœåŠ¡å±‚ (Application Servers)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  App Node 1 â”‚  â”‚  App Node 2 â”‚  â”‚  App Node 3 â”‚        â”‚
â”‚  â”‚  (Gradio)   â”‚  â”‚  (FastAPI)  â”‚  â”‚  (Gradio)   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ¨¡å‹æœåŠ¡å±‚ (Model Servers)                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  GPU Node 1 â”‚  â”‚  GPU Node 2 â”‚  â”‚  CPU Node   â”‚        â”‚
â”‚  â”‚  (vLLM)     â”‚  â”‚  (TensorRT) â”‚  â”‚  (ONNX)     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®å­˜å‚¨å±‚ (Data Storage)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  PostgreSQL â”‚  â”‚    Redis    â”‚  â”‚  MinIO/S3   â”‚        â”‚
â”‚  â”‚ (ä¸»æ•°æ®åº“)  â”‚  â”‚   (ç¼“å­˜)    â”‚  â”‚ (æ–‡ä»¶å­˜å‚¨)  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 å®¹å™¨åŒ–éƒ¨ç½²

#### 5.2.1 Dockerfile

```dockerfile
# åŸºç¡€é•œåƒ
FROM nvidia/cuda:11.8-devel-ubuntu20.04

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONPATH=/app/src:$PYTHONPATH
ENV CUDA_VISIBLE_DEVICES=0

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-dev \
    git \
    wget \
    curl \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY requirements.txt .
COPY src/ ./src/
COPY models/ ./models/
COPY configs/ ./configs/

# å®‰è£…Pythonä¾èµ–
RUN pip3 install --no-cache-dir -r requirements.txt

# åˆ›å»ºå¿…è¦ç›®å½•
RUN mkdir -p /app/logs /app/data/uploads /app/data/results

# è®¾ç½®æƒé™
RUN chmod +x /app/src/*.py

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:7861/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 7861

# å¯åŠ¨å‘½ä»¤
CMD ["python3", "src/acne_diagnosis_web.py"]
```

#### 5.2.2 Docker Compose

```yaml
version: '3.8'

services:
  # ä¸»åº”ç”¨æœåŠ¡
  acd-tcm-app:
    build: docs
    container_name: acd-tcm-app
    ports:
      - "7861:7861"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./models:/app/models
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONPATH=/app/src
    depends_on:
      - redis
      - postgres
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    restart: unless-stopped

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: acd-tcm-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped

  # PostgreSQLæ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    container_name: acd-tcm-postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=acd_tcm
      - POSTGRES_USER=acd_user
      - POSTGRES_PASSWORD=acd_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped

  # Nginxè´Ÿè½½å‡è¡¡
  nginx:
    image: nginx:alpine
    container_name: acd-tcm-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - acd-tcm-app
    restart: unless-stopped

  # ç›‘æ§æœåŠ¡
  prometheus:
    image: prom/prometheus:latest
    container_name: acd-tcm-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: acd-tcm-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning
    depends_on:
      - prometheus
    restart: unless-stopped

volumes:
  redis_data:
  postgres_data:
  prometheus_data:
  grafana_data:

networks:
  default:
    name: acd-tcm-network
```

### 5.3 Kuberneteséƒ¨ç½²

#### 5.3.1 éƒ¨ç½²æ¸…å•

```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: acd-tcm
  
---
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: acd-tcm-app
  namespace: acd-tcm
spec:
  replicas: 3
  selector:
    matchLabels:
      app: acd-tcm-app
  template:
    metadata:
      labels:
        app: acd-tcm-app
    spec:
      containers:
      - name: acd-tcm
        image: acd-tcm:latest
        ports:
        - containerPort: 7861
        env:
        - name: CUDA_VISIBLE_DEVICES
          value: "0"
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
            nvidia.com/gpu: 1
          limits:
            memory: "8Gi"
            cpu: "4"
            nvidia.com/gpu: 1
        volumeMounts:
        - name: model-storage
          mountPath: /app/models
        - name: data-storage
          mountPath: /app/data
        livenessProbe:
          httpGet:
            path: /health
            port: 7861
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 7861
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: model-pvc
      - name: data-storage
        persistentVolumeClaim:
          claimName: data-pvc
          
---
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: acd-tcm-service
  namespace: acd-tcm
spec:
  selector:
    app: acd-tcm-app
  ports:
  - protocol: TCP
    port: 80
    targetPort: 7861
  type: LoadBalancer
  
---
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: acd-tcm-ingress
  namespace: acd-tcm
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  tls:
  - hosts:
    - acd-tcm.example.com
    secretName: acd-tcm-tls
  rules:
  - host: acd-tcm.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: acd-tcm-service
            port:
              number: 80
```

#### 5.3.2 è‡ªåŠ¨æ‰©ç¼©å®¹

```yaml
# hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: acd-tcm-hpa
  namespace: acd-tcm
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: acd-tcm-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
```

### 5.4 ç›‘æ§ä¸æ—¥å¿—

#### 5.4.1 Prometheusç›‘æ§

```python
from prometheus_client import Counter, Histogram, Gauge, start_http_server

# å®šä¹‰ç›‘æ§æŒ‡æ ‡
DIAGNOSIS_COUNTER = Counter(
    'acd_tcm_diagnosis_total',
    'Total number of diagnoses',
    ['severity', 'model_version']
)

DIAGNOSIS_DURATION = Histogram(
    'acd_tcm_diagnosis_duration_seconds',
    'Time spent on diagnosis',
    ['model_version']
)

MODEL_MEMORY_USAGE = Gauge(
    'acd_tcm_model_memory_bytes',
    'Model memory usage in bytes',
    ['model_version']
)

ACTIVE_CONNECTIONS = Gauge(
    'acd_tcm_active_connections',
    'Number of active connections'
)

class MetricsCollector:
    """ç›‘æ§æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self.start_metrics_server()
    
    def start_metrics_server(self, port=8000):
        """å¯åŠ¨ç›‘æ§æŒ‡æ ‡æœåŠ¡å™¨"""
        start_http_server(port)
    
    def record_diagnosis(self, severity, model_version, duration):
        """è®°å½•è¯Šæ–­æŒ‡æ ‡"""
        DIAGNOSIS_COUNTER.labels(
            severity=severity,
            model_version=model_version
        ).inc()
        
        DIAGNOSIS_DURATION.labels(
            model_version=model_version
        ).observe(duration)
    
    def update_memory_usage(self, model_version, memory_bytes):
        """æ›´æ–°å†…å­˜ä½¿ç”¨é‡"""
        MODEL_MEMORY_USAGE.labels(
            model_version=model_version
        ).set(memory_bytes)
    
    def update_active_connections(self, count):
        """æ›´æ–°æ´»è·ƒè¿æ¥æ•°"""
        ACTIVE_CONNECTIONS.set(count)
```

#### 5.4.2 æ—¥å¿—é…ç½®

```python
import logging
from loguru import logger
import sys

class LogConfig:
    """æ—¥å¿—é…ç½®ç±»"""
    
    def __init__(self, log_level="INFO", log_file="logs/acd_tcm.log"):
        self.log_level = log_level
        self.log_file = log_file
        self.setup_logging()
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        # ç§»é™¤é»˜è®¤å¤„ç†å™¨
        logger.remove()
        
        # æ§åˆ¶å°è¾“å‡º
        logger.add(
            sys.stdout,
            level=self.log_level,
            format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | "
                   "<level>{level: <8}</level> | "
                   "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - "
                   "<level>{message}</level>",
            colorize=True
        )
        
        # æ–‡ä»¶è¾“å‡º
        logger.add(
            self.log_file,
            level=self.log_level,
            format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
            rotation="100 MB",
            retention="30 days",
            compression="zip"
        )
        
        # é”™è¯¯æ—¥å¿—å•ç‹¬è®°å½•
        logger.add(
            "logs/error.log",
            level="ERROR",
            format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
            rotation="50 MB",
            retention="90 days"
        )

# ä½¿ç”¨ç¤ºä¾‹
log_config = LogConfig()

@logger.catch
def diagnose_with_logging(image, text):
    """å¸¦æ—¥å¿—è®°å½•çš„è¯Šæ–­å‡½æ•°"""
    logger.info(f"å¼€å§‹è¯Šæ–­ï¼Œå›¾åƒå¤§å°: {image.size if image else 'None'}")
    
    try:
        start_time = time.time()
        result = inference_engine.diagnose(image, text)
        duration = time.time() - start_time
        
        logger.info(f"è¯Šæ–­å®Œæˆï¼Œè€—æ—¶: {duration:.2f}sï¼Œç»“æœ: {result['diagnosis']}")
        
        # è®°å½•ç›‘æ§æŒ‡æ ‡
        metrics_collector.record_diagnosis(
            severity=result['severity'],
            model_version="checkpoint-669",
            duration=duration
        )
        
        return result
        
    except Exception as e:
        logger.error(f"è¯Šæ–­å¤±è´¥: {str(e)}")
        raise
```

## 6. æ€§èƒ½ä¼˜åŒ–

### 6.1 æ¨¡å‹ä¼˜åŒ–

#### 6.1.1 é‡åŒ–ä¼˜åŒ–

```python
import torch
from transformers import BitsAndBytesConfig

# 4-bité‡åŒ–é…ç½®
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4"
)

# 8-bité‡åŒ–é…ç½®
quantization_config_8bit = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_threshold=6.0,
    llm_int8_has_fp16_weight=False
)

class QuantizedModel:
    """é‡åŒ–æ¨¡å‹åŒ…è£…å™¨"""
    
    def __init__(self, model_path, quantization_type="4bit"):
        self.model_path = model_path
        self.quantization_type = quantization_type
        self.model = None
        
    def load_model(self):
        """åŠ è½½é‡åŒ–æ¨¡å‹"""
        if self.quantization_type == "4bit":
            config = quantization_config
        elif self.quantization_type == "8bit":
            config = quantization_config_8bit
        else:
            config = None
            
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_path,
            quantization_config=config,
            device_map="auto",
            torch_dtype=torch.float16
        )
        
        logger.info(f"æ¨¡å‹å·²åŠ è½½ï¼Œé‡åŒ–ç±»å‹: {self.quantization_type}")
        
    def get_memory_usage(self):
        """è·å–å†…å­˜ä½¿ç”¨é‡"""
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024**3  # GB
        return 0
```

#### 6.1.2 æ¨ç†åŠ é€Ÿ

```python
from torch.compile import compile
from transformers import pipeline

class OptimizedInference:
    """ä¼˜åŒ–æ¨ç†å¼•æ“"""
    
    def __init__(self, model, tokenizer):
        self.model = model
        self.tokenizer = tokenizer
        self.compiled_model = None
        self.setup_optimization()
        
    def setup_optimization(self):
        """è®¾ç½®ä¼˜åŒ–é€‰é¡¹"""
        # å¯ç”¨torch.compile
        if hasattr(torch, 'compile'):
            self.compiled_model = torch.compile(
                self.model,
                mode="reduce-overhead",
                fullgraph=True
            )
        
        # è®¾ç½®æ¨ç†æ¨¡å¼
        self.model.eval()
        
        # ç¦ç”¨æ¢¯åº¦è®¡ç®—
        torch.set_grad_enabled(False)
        
        # å¯ç”¨CUDAä¼˜åŒ–
        if torch.cuda.is_available():
            torch.backends.cudnn.benchmark = True
            torch.backends.cuda.matmul.allow_tf32 = True
            
    @torch.inference_mode()
    def generate(self, inputs, **kwargs):
        """ä¼˜åŒ–çš„ç”Ÿæˆå‡½æ•°"""
        model = self.compiled_model or self.model
        
        # ä½¿ç”¨KVç¼“å­˜
        kwargs.setdefault('use_cache', True)
        kwargs.setdefault('do_sample', False)
        kwargs.setdefault('num_beams', 1)
        
        return model.generate(inputs, **kwargs)
        
    def batch_generate(self, batch_inputs, **kwargs):
        """æ‰¹é‡ç”Ÿæˆ"""
        # åŠ¨æ€æ‰¹å¤„ç†
        batch_size = len(batch_inputs)
        if batch_size == 1:
            return [self.generate(batch_inputs[0], **kwargs)]
            
        # æ‰¹é‡å¤„ç†
        padded_inputs = self.tokenizer.pad(
            batch_inputs,
            padding=True,
            return_tensors="pt"
        )
        
        outputs = self.generate(padded_inputs, **kwargs)
        return outputs
```

### 6.2 ç³»ç»Ÿä¼˜åŒ–

#### 6.2.1 ç¼“å­˜ç­–ç•¥

```python
import redis
from functools import wraps
import hashlib
import pickle

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, redis_host="localhost", redis_port=6379):
        self.redis_client = redis.Redis(
            host=redis_host,
            port=redis_port,
            decode_responses=False
        )
        
    def cache_key(self, func_name, *args, **kwargs):
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = f"{func_name}:{str(args)}:{str(sorted(kwargs.items()))}"
        return hashlib.md5(key_data.encode()).hexdigest()
        
    def cache_result(self, ttl=3600):
        """ç»“æœç¼“å­˜è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # ç”Ÿæˆç¼“å­˜é”®
                cache_key = self.cache_key(func.__name__, *args, **kwargs)
                
                # å°è¯•ä»ç¼“å­˜è·å–
                cached_result = self.redis_client.get(cache_key)
                if cached_result:
                    logger.info(f"ç¼“å­˜å‘½ä¸­: {func.__name__}")
                    return pickle.loads(cached_result)
                
                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)
                
                # å­˜å‚¨åˆ°ç¼“å­˜
                self.redis_client.setex(
                    cache_key,
                    ttl,
                    pickle.dumps(result)
                )
                
                logger.info(f"ç»“æœå·²ç¼“å­˜: {func.__name__}")
                return result
                
            return wrapper
        return decorator

# ä½¿ç”¨ç¤ºä¾‹
cache_manager = CacheManager()

@cache_manager.cache_result(ttl=1800)  # 30åˆ†é’Ÿç¼“å­˜
def preprocess_image(image_data):
    """å›¾åƒé¢„å¤„ç†ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # é¢„å¤„ç†é€»è¾‘
    processed = expensive_preprocessing(image_data)
    return processed

@cache_manager.cache_result(ttl=3600)  # 1å°æ—¶ç¼“å­˜
def get_model_predictions(image_features, text_features):
    """æ¨¡å‹é¢„æµ‹ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # æ¨¡å‹æ¨ç†é€»è¾‘
    predictions = model.predict(image_features, text_features)
    return predictions
```

#### 6.2.2 å¼‚æ­¥å¤„ç†

```python
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor
from queue import Queue
import threading

class AsyncDiagnosisService:
    """å¼‚æ­¥è¯Šæ–­æœåŠ¡"""
    
    def __init__(self, max_workers=4):
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.task_queue = Queue()
        self.result_cache = {}
        self.start_workers()
        
    def start_workers(self):
        """å¯åŠ¨å·¥ä½œçº¿ç¨‹"""
        for i in range(self.executor._max_workers):
            worker = threading.Thread(
                target=self._worker,
                name=f"DiagnosisWorker-{i}"
            )
            worker.daemon = True
            worker.start()
            
    def _worker(self):
        """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
        while True:
            try:
                task = self.task_queue.get(timeout=1)
                if task is None:
                    break
                    
                task_id, image, text, callback = task
                
                # æ‰§è¡Œè¯Šæ–­
                result = self._sync_diagnose(image, text)
                
                # å­˜å‚¨ç»“æœ
                self.result_cache[task_id] = result
                
                # æ‰§è¡Œå›è°ƒ
                if callback:
                    callback(task_id, result)
                    
                self.task_queue.task_done()
                
            except Exception as e:
                logger.error(f"å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")
                
    async def diagnose_async(self, image, text, task_id=None):
        """å¼‚æ­¥è¯Šæ–­"""
        if task_id is None:
            task_id = f"task_{int(time.time() * 1000)}"
            
        # æ·»åŠ åˆ°ä»»åŠ¡é˜Ÿåˆ—
        future = asyncio.Future()
        
        def callback(tid, result):
            if not future.done():
                future.set_result(result)
                
        self.task_queue.put((task_id, image, text, callback))
        
        # ç­‰å¾…ç»“æœ
        result = await future
        return result
        
    def _sync_diagnose(self, image, text):
        """åŒæ­¥è¯Šæ–­ï¼ˆåœ¨å·¥ä½œçº¿ç¨‹ä¸­æ‰§è¡Œï¼‰"""
        try:
            return inference_engine.diagnose(image, text)
        except Exception as e:
            logger.error(f"è¯Šæ–­é”™è¯¯: {e}")
            return {"error": str(e)}
            
    async def batch_diagnose(self, requests):
        """æ‰¹é‡å¼‚æ­¥è¯Šæ–­"""
        tasks = []
        for req in requests:
            task = self.diagnose_async(
                req['image'],
                req['text'],
                req.get('task_id')
            )
            tasks.append(task)
            
        results = await asyncio.gather(*tasks, return_exceptions=True)
        return results
```

### 6.3 æ•°æ®åº“ä¼˜åŒ–

#### 6.3.1 ç´¢å¼•ä¼˜åŒ–

```sql
-- è¯Šæ–­è®°å½•è¡¨ç´¢å¼•
CREATE INDEX idx_diagnoses_patient_id ON diagnoses(patient_id);
CREATE INDEX idx_diagnoses_created_at ON diagnoses(created_at);
CREATE INDEX idx_diagnoses_severity ON diagnoses(severity);
CREATE INDEX idx_diagnoses_model_version ON diagnoses(model_version);

-- å¤åˆç´¢å¼•
CREATE INDEX idx_diagnoses_patient_date ON diagnoses(patient_id, created_at DESC);
CREATE INDEX idx_diagnoses_severity_date ON diagnoses(severity, created_at DESC);

-- æ‚£è€…è¡¨ç´¢å¼•
CREATE UNIQUE INDEX idx_patients_phone ON patients(phone) WHERE phone IS NOT NULL;
CREATE UNIQUE INDEX idx_patients_email ON patients(email) WHERE email IS NOT NULL;
CREATE INDEX idx_patients_created_at ON patients(created_at);

-- åˆ†åŒºè¡¨ï¼ˆæŒ‰æ—¶é—´åˆ†åŒºï¼‰
CREATE TABLE diagnoses_2024 PARTITION OF diagnoses
FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');

CREATE TABLE diagnoses_2025 PARTITION OF diagnoses
FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');
```

#### 6.3.2 æŸ¥è¯¢ä¼˜åŒ–

```python
from sqlalchemy import text
from sqlalchemy.orm import joinedload

class OptimizedQueries:
    """ä¼˜åŒ–çš„æ•°æ®åº“æŸ¥è¯¢"""
    
    def __init__(self, db_session):
        self.db = db_session
        
    def get_patient_diagnoses_optimized(self, patient_id, limit=10):
        """ä¼˜åŒ–çš„æ‚£è€…è¯Šæ–­æŸ¥è¯¢"""
        return self.db.query(Diagnosis)\
                     .options(joinedload(Diagnosis.patient))\
                     .filter(Diagnosis.patient_id == patient_id)\
                     .order_by(Diagnosis.created_at.desc())\
                     .limit(limit)\
                     .all()
    
    def get_diagnosis_statistics_optimized(self, start_date, end_date):
        """ä¼˜åŒ–çš„è¯Šæ–­ç»Ÿè®¡æŸ¥è¯¢"""
        query = text("""
            SELECT 
                severity,
                COUNT(*) as count,
                AVG(confidence) as avg_confidence,
                DATE_TRUNC('day', created_at) as date
            FROM diagnoses 
            WHERE created_at BETWEEN :start_date AND :end_date
            GROUP BY severity, DATE_TRUNC('day', created_at)
            ORDER BY date DESC, severity
        """)
        
        return self.db.execute(query, {
            'start_date': start_date,
            'end_date': end_date
        }).fetchall()

## 7. å®‰å…¨ä¸éšç§

### 7.1 æ•°æ®å®‰å…¨

#### 7.1.1 æ•°æ®åŠ å¯†

```python
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import base64
import os

class DataEncryption:
    """æ•°æ®åŠ å¯†ç®¡ç†å™¨"""
    
    def __init__(self, password=None):
        self.password = password or os.environ.get('ENCRYPTION_KEY')
        self.key = self._derive_key()
        self.cipher = Fernet(self.key)
        
    def _derive_key(self):
        """ä»å¯†ç æ´¾ç”ŸåŠ å¯†å¯†é’¥"""
        password = self.password.encode()
        salt = b'acd_tcm_salt_2024'  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”ä½¿ç”¨éšæœºç›
        
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
        )
        
        key = base64.urlsafe_b64encode(kdf.derive(password))
        return key
        
    def encrypt_data(self, data):
        """åŠ å¯†æ•°æ®"""
        if isinstance(data, str):
            data = data.encode()
        return self.cipher.encrypt(data)
        
    def decrypt_data(self, encrypted_data):
        """è§£å¯†æ•°æ®"""
        decrypted = self.cipher.decrypt(encrypted_data)
        return decrypted.decode()
        
    def encrypt_file(self, file_path, output_path=None):
        """åŠ å¯†æ–‡ä»¶"""
        output_path = output_path or f"{file_path}.encrypted"
        
        with open(file_path, 'rb') as file:
            file_data = file.read()
            
        encrypted_data = self.cipher.encrypt(file_data)
        
        with open(output_path, 'wb') as file:
            file.write(encrypted_data)
            
        return output_path
```

#### 7.1.2 è®¿é—®æ§åˆ¶

```python
from functools import wraps
from flask_jwt_extended import verify_jwt_in_request, get_jwt_identity

class AccessControl:
    """è®¿é—®æ§åˆ¶ç®¡ç†å™¨"""
    
    ROLES = {
        'admin': ['read', 'write', 'delete', 'manage'],
        'doctor': ['read', 'write'],
        'nurse': ['read'],
        'patient': ['read_own']
    }
    
    @staticmethod
    def require_permission(permission):
        """æƒé™æ£€æŸ¥è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                verify_jwt_in_request()
                user_id = get_jwt_identity()
                
                # è·å–ç”¨æˆ·è§’è‰²
                user_role = get_user_role(user_id)
                
                # æ£€æŸ¥æƒé™
                if permission not in AccessControl.ROLES.get(user_role, []):
                    raise PermissionError(f"ç”¨æˆ·æ— æƒé™æ‰§è¡Œæ“ä½œ: {permission}")
                    
                return func(*args, **kwargs)
            return wrapper
        return decorator
    
    @staticmethod
    def require_role(required_role):
        """è§’è‰²æ£€æŸ¥è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                verify_jwt_in_request()
                user_id = get_jwt_identity()
                user_role = get_user_role(user_id)
                
                if user_role != required_role:
                    raise PermissionError(f"éœ€è¦{required_role}è§’è‰²")
                    
                return func(*args, **kwargs)
            return wrapper
        return decorator

# ä½¿ç”¨ç¤ºä¾‹
@AccessControl.require_permission('write')
def create_diagnosis(patient_id, diagnosis_data):
    """åˆ›å»ºè¯Šæ–­è®°å½•ï¼ˆéœ€è¦å†™æƒé™ï¼‰"""
    pass

@AccessControl.require_role('admin')
def delete_patient_data(patient_id):
    """åˆ é™¤æ‚£è€…æ•°æ®ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
    pass
```

### 7.2 éšç§ä¿æŠ¤

#### 7.2.1 æ•°æ®è„±æ•

```python
import re
import hashlib

class DataMasking:
    """æ•°æ®è„±æ•å¤„ç†å™¨"""
    
    @staticmethod
    def mask_phone(phone):
        """æ‰‹æœºå·è„±æ•"""
        if not phone or len(phone) < 7:
            return phone
        return phone[:3] + '****' + phone[-4:]
    
    @staticmethod
    def mask_email(email):
        """é‚®ç®±è„±æ•"""
        if not email or '@' not in email:
            return email
        username, domain = email.split('@', 1)
        if len(username) <= 2:
            return email
        return username[:2] + '***@' + domain
    
    @staticmethod
    def mask_name(name):
        """å§“åè„±æ•"""
        if not name or len(name) < 2:
            return name
        return name[0] + '*' * (len(name) - 1)
    
    @staticmethod
    def hash_sensitive_data(data, salt='acd_tcm_2024'):
        """æ•æ„Ÿæ•°æ®å“ˆå¸Œ"""
        combined = f"{data}{salt}"
        return hashlib.sha256(combined.encode()).hexdigest()
    
    def mask_patient_data(self, patient_data):
        """æ‚£è€…æ•°æ®è„±æ•"""
        masked_data = patient_data.copy()
        
        if 'phone' in masked_data:
            masked_data['phone'] = self.mask_phone(masked_data['phone'])
            
        if 'email' in masked_data:
            masked_data['email'] = self.mask_email(masked_data['email'])
            
        if 'name' in masked_data:
            masked_data['name'] = self.mask_name(masked_data['name'])
            
        return masked_data
```

## 8. æµ‹è¯•ä¸è´¨é‡ä¿è¯

### 8.1 æµ‹è¯•ç­–ç•¥

#### 8.1.1 å•å…ƒæµ‹è¯•

```python
import unittest
from unittest.mock import Mock, patch
import numpy as np
from PIL import Image

class TestAcneDiagnosis(unittest.TestCase):
    """ç—¤ç–®è¯Šæ–­å•å…ƒæµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.inference_engine = MixedInferenceEngine(
            model_path="test_model",
            engine_type="transformers"
        )
        
    def test_image_preprocessing(self):
        """æµ‹è¯•å›¾åƒé¢„å¤„ç†"""
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = Image.new('RGB', (512, 512), color='red')
        
        # é¢„å¤„ç†
        preprocessor = ImagePreprocessor()
        processed = preprocessor.preprocess(test_image)
        
        # éªŒè¯ç»“æœ
        self.assertIsNotNone(processed)
        self.assertEqual(processed.size, (224, 224))
        
    def test_diagnosis_result_format(self):
        """æµ‹è¯•è¯Šæ–­ç»“æœæ ¼å¼"""
        # æ¨¡æ‹Ÿè¯Šæ–­ç»“æœ
        mock_result = {
            'diagnosis': 'ä¸­åº¦ç—¤ç–®',
            'confidence': 0.85,
            'severity': 2,
            'recommendations': ['ä½¿ç”¨æ¸©å’Œæ´é¢äº§å“', 'é¿å…æŒ¤å‹ç—˜ç—˜']
        }
        
        # éªŒè¯ç»“æœæ ¼å¼
        self.assertIn('diagnosis', mock_result)
        self.assertIn('confidence', mock_result)
        self.assertIn('severity', mock_result)
        self.assertIsInstance(mock_result['confidence'], float)
        self.assertGreaterEqual(mock_result['confidence'], 0)
        self.assertLessEqual(mock_result['confidence'], 1)
        
    @patch('inference_engine.model.generate')
    def test_model_inference(self, mock_generate):
        """æµ‹è¯•æ¨¡å‹æ¨ç†"""
        # æ¨¡æ‹Ÿæ¨¡å‹è¾“å‡º
        mock_generate.return_value = torch.tensor([[1, 2, 3, 4]])
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_image = Image.new('RGB', (224, 224))
        test_text = "é¢éƒ¨æœ‰çº¢è‰²ä¸˜ç–¹"
        
        # æ‰§è¡Œæ¨ç†
        result = self.inference_engine.generate_response(test_image, test_text)
        
        # éªŒè¯è°ƒç”¨
        mock_generate.assert_called_once()
        self.assertIsNotNone(result)
```

#### 8.1.2 é›†æˆæµ‹è¯•

```python
import requests
import json
from io import BytesIO

class TestAPIIntegration(unittest.TestCase):
    """APIé›†æˆæµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.base_url = "http://localhost:7861"
        self.test_image_path = "test_data/acne_sample.jpg"
        
    def test_health_check(self):
        """æµ‹è¯•å¥åº·æ£€æŸ¥æ¥å£"""
        response = requests.get(f"{self.base_url}/health")
        
        self.assertEqual(response.status_code, 200)
        data = response.json()
        self.assertEqual(data['status'], 'healthy')
        
    def test_diagnosis_api(self):
        """æµ‹è¯•è¯Šæ–­API"""
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        with open(self.test_image_path, 'rb') as f:
            files = {'image': f}
            data = {
                'description': 'é¢éƒ¨æœ‰çº¢è‰²ä¸˜ç–¹',
                'patient_age': 20,
                'patient_gender': 'female'
            }
            
            response = requests.post(
                f"{self.base_url}/api/v1/diagnose",
                files=files,
                data=data
            )
            
        # éªŒè¯å“åº”
        self.assertEqual(response.status_code, 200)
        result = response.json()
        
        self.assertTrue(result['success'])
        self.assertIn('data', result)
        self.assertIn('diagnosis', result['data'])
        self.assertIn('confidence', result['data'])
        
    def test_concurrent_requests(self):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚"""
        import concurrent.futures
        
        def make_request():
            with open(self.test_image_path, 'rb') as f:
                files = {'image': f}
                response = requests.post(
                    f"{self.base_url}/api/v1/diagnose",
                    files=files
                )
            return response.status_code
            
        # å¹¶å‘æ‰§è¡Œ10ä¸ªè¯·æ±‚
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(make_request) for _ in range(10)]
            results = [future.result() for future in futures]
            
        # éªŒè¯æ‰€æœ‰è¯·æ±‚éƒ½æˆåŠŸ
        self.assertTrue(all(status == 200 for status in results))
```

### 8.2 æ€§èƒ½æµ‹è¯•

```python
import time
import psutil
import matplotlib.pyplot as plt

class PerformanceTest:
    """æ€§èƒ½æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.metrics = {
            'response_times': [],
            'memory_usage': [],
            'cpu_usage': [],
            'gpu_memory': []
        }
        
    def test_inference_speed(self, num_tests=100):
        """æµ‹è¯•æ¨ç†é€Ÿåº¦"""
        test_image = Image.new('RGB', (512, 512))
        test_text = "æµ‹è¯•æ–‡æœ¬"
        
        for i in range(num_tests):
            start_time = time.time()
            
            # æ‰§è¡Œæ¨ç†
            result = inference_engine.diagnose(test_image, test_text)
            
            end_time = time.time()
            response_time = end_time - start_time
            
            self.metrics['response_times'].append(response_time)
            
            # è®°å½•ç³»ç»Ÿèµ„æºä½¿ç”¨
            self.metrics['memory_usage'].append(psutil.virtual_memory().percent)
            self.metrics['cpu_usage'].append(psutil.cpu_percent())
            
            if torch.cuda.is_available():
                gpu_memory = torch.cuda.memory_allocated() / 1024**3
                self.metrics['gpu_memory'].append(gpu_memory)
                
        self.generate_performance_report()
        
    def test_memory_leak(self, num_iterations=1000):
        """æµ‹è¯•å†…å­˜æ³„æ¼"""
        initial_memory = psutil.Process().memory_info().rss / 1024**2
        
        for i in range(num_iterations):
            test_image = Image.new('RGB', (224, 224))
            result = inference_engine.diagnose(test_image, "æµ‹è¯•")
            
            if i % 100 == 0:
                current_memory = psutil.Process().memory_info().rss / 1024**2
                memory_increase = current_memory - initial_memory
                print(f"è¿­ä»£ {i}: å†…å­˜å¢é•¿ {memory_increase:.2f} MB")
                
                # å¦‚æœå†…å­˜å¢é•¿è¶…è¿‡é˜ˆå€¼ï¼Œå¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼
                if memory_increase > 500:  # 500MBé˜ˆå€¼
                    print("è­¦å‘Šï¼šå¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼")
                    
    def generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        avg_response_time = np.mean(self.metrics['response_times'])
        p95_response_time = np.percentile(self.metrics['response_times'], 95)
        p99_response_time = np.percentile(self.metrics['response_times'], 99)
        
        print(f"å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s")
        print(f"P95å“åº”æ—¶é—´: {p95_response_time:.3f}s")
        print(f"P99å“åº”æ—¶é—´: {p99_response_time:.3f}s")
        
        # ç”Ÿæˆæ€§èƒ½å›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        
        # å“åº”æ—¶é—´åˆ†å¸ƒ
        axes[0, 0].hist(self.metrics['response_times'], bins=50)
        axes[0, 0].set_title('å“åº”æ—¶é—´åˆ†å¸ƒ')
        axes[0, 0].set_xlabel('æ—¶é—´(ç§’)')
        
        # å†…å­˜ä½¿ç”¨è¶‹åŠ¿
        axes[0, 1].plot(self.metrics['memory_usage'])
        axes[0, 1].set_title('å†…å­˜ä½¿ç”¨è¶‹åŠ¿')
        axes[0, 1].set_ylabel('å†…å­˜ä½¿ç”¨ç‡(%)')
        
        # CPUä½¿ç”¨è¶‹åŠ¿
        axes[1, 0].plot(self.metrics['cpu_usage'])
        axes[1, 0].set_title('CPUä½¿ç”¨è¶‹åŠ¿')
        axes[1, 0].set_ylabel('CPUä½¿ç”¨ç‡(%)')
        
        # GPUå†…å­˜ä½¿ç”¨
        if self.metrics['gpu_memory']:
            axes[1, 1].plot(self.metrics['gpu_memory'])
            axes[1, 1].set_title('GPUå†…å­˜ä½¿ç”¨')
            axes[1, 1].set_ylabel('GPUå†…å­˜(GB)')
        
        plt.tight_layout()
        plt.savefig('performance_report.png')
        print("æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ° performance_report.png")
```

## 9. é¡¹ç›®æ€»ç»“

### 9.1 æŠ€æœ¯æˆæœ

1. **æ¨¡å‹æ€§èƒ½**ï¼šåŸºäºQwen2.5-VLçš„ç—¤ç–®è¯Šæ–­æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¾¾åˆ°89.2%çš„å‡†ç¡®ç‡
2. **ç³»ç»Ÿæ¶æ„**ï¼šæ„å»ºäº†å®Œæ•´çš„å¤šæ¨¡æ€è¯Šæ–­ç³»ç»Ÿï¼Œæ”¯æŒå›¾åƒå’Œæ–‡æœ¬è¾“å…¥
3. **éƒ¨ç½²æ–¹æ¡ˆ**ï¼šæä¾›äº†å¤šç§éƒ¨ç½²é€‰é¡¹ï¼Œé€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šé€šè¿‡é‡åŒ–ã€ç¼“å­˜ã€å¼‚æ­¥å¤„ç†ç­‰æŠ€æœ¯å®ç°é«˜æ•ˆæ¨ç†

### 9.2 åˆ›æ–°ç‚¹

1. **ä¸­è¥¿åŒ»ç»“åˆ**ï¼šèåˆç°ä»£åŒ»å­¦åˆ†ç±»å’Œä¼ ç»Ÿä¸­åŒ»ç†è®º
2. **å¤šæ¨¡æ€èåˆ**ï¼šç»“åˆå›¾åƒç‰¹å¾å’Œæ–‡æœ¬æè¿°æé«˜è¯Šæ–­å‡†ç¡®æ€§
3. **æ™ºèƒ½æ¨ç†å¼•æ“**ï¼šæ”¯æŒå¤šç§æ¨ç†åç«¯çš„è‡ªé€‚åº”é€‰æ‹©
4. **å®æ—¶è¯Šæ–­**ï¼šä¼˜åŒ–æ¨¡å‹ç»“æ„æ”¯æŒå®æ—¶åœ¨çº¿è¯Šæ–­

### 9.3 åº”ç”¨ä»·å€¼

1. **åŒ»ç–—è¾…åŠ©**ï¼šä¸ºçš®è‚¤ç§‘åŒ»ç”Ÿæä¾›æ™ºèƒ½è¯Šæ–­è¾…åŠ©å·¥å…·
2. **å¥åº·ç®¡ç†**ï¼šå¸®åŠ©ç”¨æˆ·è¿›è¡Œæ—¥å¸¸çš®è‚¤å¥åº·ç›‘æµ‹
3. **åŒ»ç–—æ™®åŠ**ï¼šé™ä½ä¸“ä¸šåŒ»ç–—æœåŠ¡çš„é—¨æ§›
4. **æ•°æ®ç§¯ç´¯**ï¼šä¸ºçš®è‚¤ç—…ç ”ç©¶æä¾›å¤§è§„æ¨¡æ•°æ®æ”¯æŒ

### 9.4 æœªæ¥å‘å±•

1. **æ¨¡å‹ä¼˜åŒ–**ï¼šæŒç»­æ”¹è¿›æ¨¡å‹æ¶æ„å’Œè®­ç»ƒç­–ç•¥
2. **åŠŸèƒ½æ‰©å±•**ï¼šæ”¯æŒæ›´å¤šçš®è‚¤ç–¾ç—…çš„è¯Šæ–­
3. **ç§»åŠ¨ç«¯é€‚é…**ï¼šå¼€å‘ç§»åŠ¨åº”ç”¨ç‰ˆæœ¬
4. **å›½é™…åŒ–**ï¼šæ”¯æŒå¤šè¯­è¨€å’Œä¸åŒåœ°åŒºçš„åŒ»ç–—æ ‡å‡†

---

**æŠ¥å‘Šç¼–å†™æ—¥æœŸ**ï¼š2025å¹´8æœˆ
**ç‰ˆæœ¬**ï¼šv1.0
**ç¼–å†™äººå‘˜**ï¼šACD-TCMå¼€å‘å›¢é˜Ÿ
